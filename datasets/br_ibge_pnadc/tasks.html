<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pipelines.datasets.br_ibge_pnadc.tasks API documentation</title>
<meta name="description" content="Tasks for br_ibge_pnadc" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pipelines.datasets.br_ibge_pnadc.tasks</code></h1>
</header>
<section id="section-intro">
<p>Tasks for br_ibge_pnadc</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;
Tasks for br_ibge_pnadc
&#34;&#34;&#34;
# pylint: disable=invalid-name,unnecessary-dunder-call
import zipfile
import os
from glob import glob

import requests
from tqdm import tqdm
import pandas as pd
import numpy as np
from prefect import task

from pipelines.utils.utils import log
from pipelines.datasets.br_ibge_pnadc.constants import constants as pnad_constants


@task
def get_url_from_template(year: int, quarter: int)-&gt; str:
    &#34;&#34;&#34;Return the url for the PNAD microdata file for a given year and month.
    Args:
        year (int): Year of the microdata file.
        quarter (int): Quarter of the microdata file.
    Returns:
        str: url
    &#34;&#34;&#34;
    download_page=&#39;https://ftp.ibge.gov.br/Trabalho_e_Rendimento/Pesquisa_Nacional_por_Amostra_de_Domicilios_continua/Trimestral/Microdados/2021/&#39;
    response = requests.get(download_page, timeout=5)
    hrefs = [k for k in response.text.split(&#39;href=&#34;&#39;)[1:] if k.__contains__(&#39;zip&#39;)]
    hrefs = [k.split(&#39;&#34;&#39;)[0] for k in hrefs]
    href = hrefs[0]
    href = href.replace(&#39;2021&#39;, str(year))
    filename = href.replace(&#39;01&#39;, str(quarter).zfill(2))

    url = pnad_constants.URL_PREFIX.value + &#39;/{year}/{filename}&#39;
    return url.format(year=year, filename=filename)


@task
def download_txt(url, chunk_size=128, mkdir=False) -&gt; str:
    &#34;&#34;&#34;
    Gets all csv files from a url and saves them to a directory.
    &#34;&#34;&#34;
    if mkdir:
        os.system(&#34;mkdir -p /tmp/data/input/&#34;)

    request_headers = {
        &#34;User-Agent&#34;: &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36&#34;,
    }
    r = requests.get(url, headers=request_headers, stream=True, timeout=10)
    save_path = &#34;/tmp/data/&#34;
    save_path = save_path + url.split(&#34;/&#34;)[-1]
    with open(save_path, &#34;wb&#34;) as fd:
        for chunk in tqdm(r.iter_content(chunk_size=chunk_size)):
            fd.write(chunk)

    with zipfile.ZipFile(save_path) as z:
        z.extractall(&#34;/tmp/data/input&#34;)
    os.system(&#39;cd /tmp/data/input; find . -type f ! -iname &#34;*.txt&#34; -delete&#39;)
    filepath = glob(&#34;/tmp/data/input/*.txt&#34;)[0]

    return filepath


@task
def build_parquet_files(filepath: str) -&gt; str:
    &#34;&#34;&#34;
    Build partitions from a given file.
    &#34;&#34;&#34;

    os.system(&#34;mkdir -p /tmp/data/staging/&#34;)
    # read file
    chunks = pd.read_fwf(
            filepath,
            widths=pnad_constants.COLUMNS_WIDTHS.value,
            names=pnad_constants.COLUMNS_NAMES.value,
            header=None,
            encoding=&#34;latin-1&#34;,
            dtype=str,
            chunksize=10000,
        )
    
    for i, chunk in enumerate(chunks):
        # partition by year, quarter and region
        chunk.rename(
            columns={
                &#34;UF&#34;: &#34;id_uf&#34;,
                &#34;Estrato&#34;: &#34;id_estrato&#34;,
                &#34;UPA&#34;: &#34;id_upa&#34;,
                &#34;Capital&#34;: &#34;capital&#34;,
                &#34;RM_RIDE&#34;: &#34;rm_ride&#34;,
                &#34;Trimestre&#34;: &#34;trimestre&#34;,
                &#34;Ano&#34;: &#34;ano&#34;,
            },
            inplace=True,
        )
        chunk[&#34;sigla_uf&#34;] = chunk[&#34;id_uf&#34;].map(pnad_constants.map_codigo_sigla_uf.value)
        chunk[&#34;id_domicilio&#34;] = chunk[&#34;id_estrato&#34;] + chunk[&#34;V1008&#34;] + chunk[&#34;V1014&#34;]


        chunk[&#34;habitual&#34;] = [np.nan] * len(chunk)
        chunk[&#34;efetivo&#34;] = [np.nan] * len(chunk)
        ordered_columns = pnad_constants.COLUMNS_ORDER.value
        chunk = chunk[ordered_columns]

        # save to parquet
        chunk.to_parquet(
            f&#34;/tmp/data/staging/microdados_{i}.parquet&#34;,
            index=False,
        )
        log(i)

    # print number of parquet files
    total_files = len(glob(&#34;/tmp/data/staging/*.parquet&#34;))
    log(f&#34;Total of {total_files} parquet files created.&#34;)

    return &#34;/tmp/data/staging/&#34;


@task
def save_partitions(filepath: str) -&gt; str:
    &#34;&#34;&#34;
    Save partitions to disk.

    Args:
        filepath (str): Path to the file used to build the partitions.
    
    Returns:
        str: Path to the saved file.

    &#34;&#34;&#34;
    os.system(&#34;mkdir -p /tmp/data/output/&#34;)

    # get all parquet files
    parquet_files = glob(f&#34;{filepath}*.parquet&#34;)
    # read all parquet files
    df = pd.concat([pd.read_parquet(f) for f in parquet_files])

    trimestre = df[&#34;trimestre&#34;].unique()[0]
    ano = df[&#34;ano&#34;].unique()[0]
    df.drop(columns=[&#34;trimestre&#34;, &#34;ano&#34;], inplace=True)
    ufs = df[&#34;sigla_uf&#34;].unique()

    for uf in ufs:
        df_uf = df[df[&#34;sigla_uf&#34;] == uf]
        df_uf.drop(columns=[&#34;sigla_uf&#34;], inplace=True)
        os.system(
            &#34;mkdir -p /tmp/data/output/ano={ano}/trimestre={trimestre}/sigla_uf={uf}&#34;.format(
                ano=ano, trimestre=trimestre, uf=uf
            )
        )
        df_uf.to_csv(
            f&#34;/tmp/data/output/ano={ano}/trimestre={trimestre}/sigla_uf={uf}/microdados.csv&#34;,
            index=False,
        )

    return &#34;/tmp/data/output/&#34;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pipelines.datasets.br_ibge_pnadc.tasks.build_parquet_files"><code class="name flex">
<span>def <span class="ident">build_parquet_files</span></span>(<span>filepath: str) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Build partitions from a given file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task
def build_parquet_files(filepath: str) -&gt; str:
    &#34;&#34;&#34;
    Build partitions from a given file.
    &#34;&#34;&#34;

    os.system(&#34;mkdir -p /tmp/data/staging/&#34;)
    # read file
    chunks = pd.read_fwf(
            filepath,
            widths=pnad_constants.COLUMNS_WIDTHS.value,
            names=pnad_constants.COLUMNS_NAMES.value,
            header=None,
            encoding=&#34;latin-1&#34;,
            dtype=str,
            chunksize=10000,
        )
    
    for i, chunk in enumerate(chunks):
        # partition by year, quarter and region
        chunk.rename(
            columns={
                &#34;UF&#34;: &#34;id_uf&#34;,
                &#34;Estrato&#34;: &#34;id_estrato&#34;,
                &#34;UPA&#34;: &#34;id_upa&#34;,
                &#34;Capital&#34;: &#34;capital&#34;,
                &#34;RM_RIDE&#34;: &#34;rm_ride&#34;,
                &#34;Trimestre&#34;: &#34;trimestre&#34;,
                &#34;Ano&#34;: &#34;ano&#34;,
            },
            inplace=True,
        )
        chunk[&#34;sigla_uf&#34;] = chunk[&#34;id_uf&#34;].map(pnad_constants.map_codigo_sigla_uf.value)
        chunk[&#34;id_domicilio&#34;] = chunk[&#34;id_estrato&#34;] + chunk[&#34;V1008&#34;] + chunk[&#34;V1014&#34;]


        chunk[&#34;habitual&#34;] = [np.nan] * len(chunk)
        chunk[&#34;efetivo&#34;] = [np.nan] * len(chunk)
        ordered_columns = pnad_constants.COLUMNS_ORDER.value
        chunk = chunk[ordered_columns]

        # save to parquet
        chunk.to_parquet(
            f&#34;/tmp/data/staging/microdados_{i}.parquet&#34;,
            index=False,
        )
        log(i)

    # print number of parquet files
    total_files = len(glob(&#34;/tmp/data/staging/*.parquet&#34;))
    log(f&#34;Total of {total_files} parquet files created.&#34;)

    return &#34;/tmp/data/staging/&#34;</code></pre>
</details>
</dd>
<dt id="pipelines.datasets.br_ibge_pnadc.tasks.download_txt"><code class="name flex">
<span>def <span class="ident">download_txt</span></span>(<span>url, chunk_size=128, mkdir=False) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Gets all csv files from a url and saves them to a directory.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task
def download_txt(url, chunk_size=128, mkdir=False) -&gt; str:
    &#34;&#34;&#34;
    Gets all csv files from a url and saves them to a directory.
    &#34;&#34;&#34;
    if mkdir:
        os.system(&#34;mkdir -p /tmp/data/input/&#34;)

    request_headers = {
        &#34;User-Agent&#34;: &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36&#34;,
    }
    r = requests.get(url, headers=request_headers, stream=True, timeout=10)
    save_path = &#34;/tmp/data/&#34;
    save_path = save_path + url.split(&#34;/&#34;)[-1]
    with open(save_path, &#34;wb&#34;) as fd:
        for chunk in tqdm(r.iter_content(chunk_size=chunk_size)):
            fd.write(chunk)

    with zipfile.ZipFile(save_path) as z:
        z.extractall(&#34;/tmp/data/input&#34;)
    os.system(&#39;cd /tmp/data/input; find . -type f ! -iname &#34;*.txt&#34; -delete&#39;)
    filepath = glob(&#34;/tmp/data/input/*.txt&#34;)[0]

    return filepath</code></pre>
</details>
</dd>
<dt id="pipelines.datasets.br_ibge_pnadc.tasks.get_url_from_template"><code class="name flex">
<span>def <span class="ident">get_url_from_template</span></span>(<span>year: int, quarter: int) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Return the url for the PNAD microdata file for a given year and month.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>year</code></strong> :&ensp;<code>int</code></dt>
<dd>Year of the microdata file.</dd>
<dt><strong><code>quarter</code></strong> :&ensp;<code>int</code></dt>
<dd>Quarter of the microdata file.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>url</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task
def get_url_from_template(year: int, quarter: int)-&gt; str:
    &#34;&#34;&#34;Return the url for the PNAD microdata file for a given year and month.
    Args:
        year (int): Year of the microdata file.
        quarter (int): Quarter of the microdata file.
    Returns:
        str: url
    &#34;&#34;&#34;
    download_page=&#39;https://ftp.ibge.gov.br/Trabalho_e_Rendimento/Pesquisa_Nacional_por_Amostra_de_Domicilios_continua/Trimestral/Microdados/2021/&#39;
    response = requests.get(download_page, timeout=5)
    hrefs = [k for k in response.text.split(&#39;href=&#34;&#39;)[1:] if k.__contains__(&#39;zip&#39;)]
    hrefs = [k.split(&#39;&#34;&#39;)[0] for k in hrefs]
    href = hrefs[0]
    href = href.replace(&#39;2021&#39;, str(year))
    filename = href.replace(&#39;01&#39;, str(quarter).zfill(2))

    url = pnad_constants.URL_PREFIX.value + &#39;/{year}/{filename}&#39;
    return url.format(year=year, filename=filename)</code></pre>
</details>
</dd>
<dt id="pipelines.datasets.br_ibge_pnadc.tasks.save_partitions"><code class="name flex">
<span>def <span class="ident">save_partitions</span></span>(<span>filepath: str) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Save partitions to disk.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the file used to build the partitions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Path to the saved file.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task
def save_partitions(filepath: str) -&gt; str:
    &#34;&#34;&#34;
    Save partitions to disk.

    Args:
        filepath (str): Path to the file used to build the partitions.
    
    Returns:
        str: Path to the saved file.

    &#34;&#34;&#34;
    os.system(&#34;mkdir -p /tmp/data/output/&#34;)

    # get all parquet files
    parquet_files = glob(f&#34;{filepath}*.parquet&#34;)
    # read all parquet files
    df = pd.concat([pd.read_parquet(f) for f in parquet_files])

    trimestre = df[&#34;trimestre&#34;].unique()[0]
    ano = df[&#34;ano&#34;].unique()[0]
    df.drop(columns=[&#34;trimestre&#34;, &#34;ano&#34;], inplace=True)
    ufs = df[&#34;sigla_uf&#34;].unique()

    for uf in ufs:
        df_uf = df[df[&#34;sigla_uf&#34;] == uf]
        df_uf.drop(columns=[&#34;sigla_uf&#34;], inplace=True)
        os.system(
            &#34;mkdir -p /tmp/data/output/ano={ano}/trimestre={trimestre}/sigla_uf={uf}&#34;.format(
                ano=ano, trimestre=trimestre, uf=uf
            )
        )
        df_uf.to_csv(
            f&#34;/tmp/data/output/ano={ano}/trimestre={trimestre}/sigla_uf={uf}/microdados.csv&#34;,
            index=False,
        )

    return &#34;/tmp/data/output/&#34;</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pipelines.datasets.br_ibge_pnadc" href="index.html">pipelines.datasets.br_ibge_pnadc</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pipelines.datasets.br_ibge_pnadc.tasks.build_parquet_files" href="#pipelines.datasets.br_ibge_pnadc.tasks.build_parquet_files">build_parquet_files</a></code></li>
<li><code><a title="pipelines.datasets.br_ibge_pnadc.tasks.download_txt" href="#pipelines.datasets.br_ibge_pnadc.tasks.download_txt">download_txt</a></code></li>
<li><code><a title="pipelines.datasets.br_ibge_pnadc.tasks.get_url_from_template" href="#pipelines.datasets.br_ibge_pnadc.tasks.get_url_from_template">get_url_from_template</a></code></li>
<li><code><a title="pipelines.datasets.br_ibge_pnadc.tasks.save_partitions" href="#pipelines.datasets.br_ibge_pnadc.tasks.save_partitions">save_partitions</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>